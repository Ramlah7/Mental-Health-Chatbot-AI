{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1977,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015180265654648956,
      "grad_norm": 66.32616424560547,
      "learning_rate": 0.0002,
      "loss": 8.7635,
      "step": 1
    },
    {
      "epoch": 0.07590132827324478,
      "grad_norm": 8.045270919799805,
      "learning_rate": 0.00019504299443601417,
      "loss": 3.7762,
      "step": 50
    },
    {
      "epoch": 0.15180265654648956,
      "grad_norm": 7.163363456726074,
      "learning_rate": 0.00018998482549317146,
      "loss": 2.6353,
      "step": 100
    },
    {
      "epoch": 0.22770398481973433,
      "grad_norm": 4.130016803741455,
      "learning_rate": 0.0001849266565503288,
      "loss": 2.3579,
      "step": 150
    },
    {
      "epoch": 0.3036053130929791,
      "grad_norm": 5.770744323730469,
      "learning_rate": 0.0001798684876074861,
      "loss": 2.2721,
      "step": 200
    },
    {
      "epoch": 0.3795066413662239,
      "grad_norm": 4.075303554534912,
      "learning_rate": 0.0001748103186646434,
      "loss": 2.057,
      "step": 250
    },
    {
      "epoch": 0.45540796963946867,
      "grad_norm": 3.2648487091064453,
      "learning_rate": 0.00016975214972180072,
      "loss": 2.0313,
      "step": 300
    },
    {
      "epoch": 0.5313092979127134,
      "grad_norm": 3.7320828437805176,
      "learning_rate": 0.00016469398077895804,
      "loss": 2.0835,
      "step": 350
    },
    {
      "epoch": 0.6072106261859582,
      "grad_norm": 4.366353511810303,
      "learning_rate": 0.00015963581183611533,
      "loss": 1.9189,
      "step": 400
    },
    {
      "epoch": 0.683111954459203,
      "grad_norm": 4.082879066467285,
      "learning_rate": 0.00015457764289327264,
      "loss": 1.9833,
      "step": 450
    },
    {
      "epoch": 0.7590132827324478,
      "grad_norm": 3.1484389305114746,
      "learning_rate": 0.00014951947395042996,
      "loss": 1.9634,
      "step": 500
    },
    {
      "epoch": 0.8349146110056926,
      "grad_norm": 4.207011699676514,
      "learning_rate": 0.00014446130500758725,
      "loss": 2.129,
      "step": 550
    },
    {
      "epoch": 0.9108159392789373,
      "grad_norm": 4.064653396606445,
      "learning_rate": 0.0001394031360647446,
      "loss": 1.8989,
      "step": 600
    },
    {
      "epoch": 0.9867172675521821,
      "grad_norm": 3.4666969776153564,
      "learning_rate": 0.00013434496712190188,
      "loss": 2.0897,
      "step": 650
    },
    {
      "epoch": 1.0622390891840607,
      "grad_norm": 4.252144813537598,
      "learning_rate": 0.00012928679817905916,
      "loss": 1.4608,
      "step": 700
    },
    {
      "epoch": 1.1381404174573055,
      "grad_norm": 4.15922737121582,
      "learning_rate": 0.0001242286292362165,
      "loss": 1.4386,
      "step": 750
    },
    {
      "epoch": 1.2140417457305503,
      "grad_norm": 3.2927963733673096,
      "learning_rate": 0.0001191704602933738,
      "loss": 1.3764,
      "step": 800
    },
    {
      "epoch": 1.2899430740037952,
      "grad_norm": 3.212390661239624,
      "learning_rate": 0.00011411229135053112,
      "loss": 1.3093,
      "step": 850
    },
    {
      "epoch": 1.3658444022770397,
      "grad_norm": 3.2727808952331543,
      "learning_rate": 0.00010905412240768841,
      "loss": 1.4397,
      "step": 900
    },
    {
      "epoch": 1.4417457305502848,
      "grad_norm": 3.3107433319091797,
      "learning_rate": 0.00010399595346484574,
      "loss": 1.4737,
      "step": 950
    },
    {
      "epoch": 1.5176470588235293,
      "grad_norm": 3.906353235244751,
      "learning_rate": 9.893778452200304e-05,
      "loss": 1.387,
      "step": 1000
    },
    {
      "epoch": 1.5935483870967742,
      "grad_norm": 4.377844333648682,
      "learning_rate": 9.387961557916035e-05,
      "loss": 1.3687,
      "step": 1050
    },
    {
      "epoch": 1.669449715370019,
      "grad_norm": 3.358412981033325,
      "learning_rate": 8.882144663631766e-05,
      "loss": 1.4378,
      "step": 1100
    },
    {
      "epoch": 1.7453510436432638,
      "grad_norm": 4.028411388397217,
      "learning_rate": 8.376327769347496e-05,
      "loss": 1.4097,
      "step": 1150
    },
    {
      "epoch": 1.8212523719165086,
      "grad_norm": 4.8505144119262695,
      "learning_rate": 7.870510875063228e-05,
      "loss": 1.3279,
      "step": 1200
    },
    {
      "epoch": 1.8971537001897532,
      "grad_norm": 3.5906307697296143,
      "learning_rate": 7.364693980778958e-05,
      "loss": 1.3362,
      "step": 1250
    },
    {
      "epoch": 1.9730550284629982,
      "grad_norm": 4.056000232696533,
      "learning_rate": 6.85887708649469e-05,
      "loss": 1.3196,
      "step": 1300
    },
    {
      "epoch": 2.0485768500948764,
      "grad_norm": 3.247941255569458,
      "learning_rate": 6.353060192210421e-05,
      "loss": 1.0796,
      "step": 1350
    },
    {
      "epoch": 2.1244781783681215,
      "grad_norm": 3.694875955581665,
      "learning_rate": 5.847243297926151e-05,
      "loss": 1.0248,
      "step": 1400
    },
    {
      "epoch": 2.200379506641366,
      "grad_norm": 3.630674362182617,
      "learning_rate": 5.3414264036418815e-05,
      "loss": 1.0106,
      "step": 1450
    },
    {
      "epoch": 2.276280834914611,
      "grad_norm": 4.102453708648682,
      "learning_rate": 4.835609509357612e-05,
      "loss": 0.9776,
      "step": 1500
    },
    {
      "epoch": 2.3521821631878557,
      "grad_norm": 2.881077527999878,
      "learning_rate": 4.329792615073344e-05,
      "loss": 0.9708,
      "step": 1550
    },
    {
      "epoch": 2.4280834914611007,
      "grad_norm": 3.1162943840026855,
      "learning_rate": 3.823975720789075e-05,
      "loss": 0.9906,
      "step": 1600
    },
    {
      "epoch": 2.5039848197343453,
      "grad_norm": 3.341960906982422,
      "learning_rate": 3.3181588265048056e-05,
      "loss": 0.9556,
      "step": 1650
    },
    {
      "epoch": 2.5798861480075903,
      "grad_norm": 2.933152198791504,
      "learning_rate": 2.8123419322205364e-05,
      "loss": 0.9031,
      "step": 1700
    },
    {
      "epoch": 2.655787476280835,
      "grad_norm": 2.6717283725738525,
      "learning_rate": 2.306525037936267e-05,
      "loss": 0.957,
      "step": 1750
    },
    {
      "epoch": 2.7316888045540795,
      "grad_norm": 3.742217779159546,
      "learning_rate": 1.800708143651998e-05,
      "loss": 0.9854,
      "step": 1800
    },
    {
      "epoch": 2.8075901328273245,
      "grad_norm": 3.2770073413848877,
      "learning_rate": 1.294891249367729e-05,
      "loss": 0.9643,
      "step": 1850
    },
    {
      "epoch": 2.8834914611005695,
      "grad_norm": 3.791140079498291,
      "learning_rate": 7.890743550834597e-06,
      "loss": 0.9572,
      "step": 1900
    },
    {
      "epoch": 2.959392789373814,
      "grad_norm": 4.103173732757568,
      "learning_rate": 2.832574607991907e-06,
      "loss": 0.9417,
      "step": 1950
    }
  ],
  "logging_steps": 50,
  "max_steps": 1977,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1032756756480000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
